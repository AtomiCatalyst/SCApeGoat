{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Samuel Karkache\n",
    "Trey Marcantonio\n",
    "\n",
    "Differential Power Analysis metrics for Security Analysis of Integrated Circuits MQP. These DPA metric functions will be able to read multiple file types (ChipWhisper, LeCroyDSO, etc...) and perform different metric analysis on the associated power traces. This provides an interface for traces stored in different file formats and allows for efficient processing of large datasets. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f9edd07ef33dc4d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T20:04:10.153657300Z",
     "start_time": "2023-11-17T20:04:10.120870900Z"
    }
   },
   "id": "18d57964c6d725bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Signal to Noise Ratio metric \n",
    "#   - labels: An array of arrays. Each index of the labels array (i.e. labels[0])\n",
    "#     is a label group containing the corresponding power traces.\n",
    "# return: the SNR signal \n",
    "def signal_to_noise_ratio(labels):\n",
    "   # statistical mean and variances of each set \n",
    "   set_means = []\n",
    "   set_variances = []\n",
    "   \n",
    "   for label in labels:\n",
    "       set_means.append(np.mean(label, axis=0)) # take the mean along the column\n",
    "       set_variances.append(np.var(label, axis=0)) # take the variance along the column\n",
    "   \n",
    "   # calculate overall mean and variance\n",
    "   overall_mean= np.mean(set_means, axis=0)              \n",
    "   overall_variance = np.var(set_variances, axis=0)\n",
    "\n",
    "   # perform SNR calculation\n",
    "   l_d = np.zeros(len(set_means[0]))\n",
    "   for mean in set_means:\n",
    "       l_d = np.add(l_d, np.square(np.subtract(mean, overall_mean)))\n",
    "   l_n = overall_variance\n",
    "\n",
    "   snr = np.divide(l_d, l_n)\n",
    "\n",
    "   return snr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "303cf73826670303"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Score metric: Ranks each key guess in a key partition based on a scoring function\n",
    "#   - traces: The trace set to be evaluated\n",
    "#   - score_fcn: Function callback that takes two arguments, traces and a guess candidate\n",
    "#                and returns a \"score\" such that the higher the value, the more likely the \n",
    "#                key candidate is the actual key\n",
    "#   - partitions: The number of partitions of the key full key.\n",
    "# return: A 2D array rank. The value rank[i] are the key guess rankings for partition i. \n",
    "#         The value of rank[i][0] is the highest ranked key guess for partition i.\n",
    "def score_and_rank(traces, score_fcn, key_candidates, partitions):\n",
    "        ranks = []\n",
    "        # for each key partition        \n",
    "        for i in range(partitions): \n",
    "            dtype = [('key', int), ('score', 'float64')]\n",
    "            partition_scores = np.array([], dtype=dtype)\n",
    "            \n",
    "            # for each key guess in the partition score the value and add to list\n",
    "            for k in key_candidates:\n",
    "                score_k = score_fcn(traces, k)\n",
    "                key_score = np.array([(k, score_k)], dtype=dtype)\n",
    "                partition_scores = np.append(partition_scores, key_score)\n",
    "                \n",
    "            # rank each key where partition_ranks[0] is the key that scored the highest\n",
    "            partition_ranks = np.array([key_score[0] for key_score in np.sort(partition_scores, order='score')[::-1]])\n",
    "            \n",
    "            ranks.append(partition_ranks)\n",
    "        return ranks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T22:59:35.782453700Z",
     "start_time": "2023-11-16T22:59:35.758435Z"
    }
   },
   "id": "45dde6602bcdcbc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Success Rate and Guessing Entropy Metric: Analyzes\n",
    "\n",
    "def success_rate_guessing_entropy(num_experiments):\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a8f43e33d17956"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# T-test with TVlA metric:  In general |t| > th where th = 4.5 means that the system leaks information about the cryptographic key.\n",
    "#   - fixed:  Trace set recorded with a fixed plaintext \n",
    "#   - random: Trace set recorded with a random set of plaintexts\n",
    "# return: t_statistic and p-value\n",
    "def t_test_tvla(fixed, random):\n",
    "    \n",
    "    # determine t_statistic and p-value using scipy \n",
    "    t_statistic, p_value = stats.ttest_ind(fixed, random)\n",
    "    \n",
    "    # high t-statistic and low p-values indicate that a given time sample leaks information\n",
    "    return t_statistic, p_value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd9e04554a871567"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
