{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Side Channel Analysis Metric API\n",
    "There exists very few comprehensive open-source libraries for side-channel analysis. Libraries that do exist are difficult to use and lack the proper documentation. This Jupyter Notebook outlines some of the most useful metrics when conducting side channel analysis in an easy to understand medium. These metrics do not perform an attack, rather they are used to assess gain insight into the cryptographic system. Many of the metrics in this API require data to be pre-formatted prior to use. However, each metric explains what programmer needs to provide. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f9edd07ef33dc4d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T01:52:12.529407400Z",
     "start_time": "2023-11-24T01:52:12.468646600Z"
    }
   },
   "id": "18d57964c6d725bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Signal-to-Noise Ratio \n",
    "The signal-to-noise ratio of a signal is defined as the ratio of a signal's data component to the signal's noise component. For side-channel analysis, the SNR of a power trace relates to the ability for an attacker to obtain information from a power trace during an attack. The effectiveness of side channel attack increases for larger SNR values since the signal leakage is more prominent relative to the noise of the signal.\n",
    "\n",
    "$$\n",
    "SNR = \\frac{VAR(L_d)}{VAR(L_n)} = \\frac{\\sum_{v=0}^{V} (\\hat{\\mu_v}^2 - \\hat{\\mu})^2}{\\hat{\\sigma}^2}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec9b8e1b8e3bf69b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Signal to Noise Ratio metric \n",
    "#   - labels: An array of arrays. Each index of the labels array (i.e. labels[0])\n",
    "#     is a label group containing the corresponding power traces.\n",
    "# return: the SNR signal \n",
    "def signal_to_noise_ratio(labels):\n",
    "   # statistical mean and variances of each set \n",
    "   set_means = []\n",
    "   set_variances = []\n",
    "   \n",
    "   for label in labels:\n",
    "       set_means.append(np.mean(label, axis=0)) # take the mean along the column\n",
    "       set_variances.append(np.var(label, axis=0)) # take the variance along the column\n",
    "   \n",
    "   # calculate overall mean and variance\n",
    "   overall_mean= np.mean(set_means, axis=0)              \n",
    "   overall_variance = np.var(set_variances, axis=0)\n",
    "\n",
    "   # perform SNR calculation\n",
    "   l_d = np.zeros(len(set_means[0]))\n",
    "   for mean in set_means:\n",
    "       l_d = np.add(l_d, np.square(np.subtract(mean, overall_mean)))\n",
    "   l_n = overall_variance\n",
    "\n",
    "   snr = np.divide(l_d, l_n)\n",
    "\n",
    "   return snr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T01:52:12.603279300Z",
     "start_time": "2023-11-24T01:52:12.478555900Z"
    }
   },
   "id": "303cf73826670303"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Score metric: Ranks each key guess in a key partition based on a scoring function\n",
    "#   - traces: The trace set to be evaluated\n",
    "#   - score_fcn: Function callback that takes two arguments, traces and a guess candidate\n",
    "#                and returns a \"score\" such that the higher the value, the more likely the \n",
    "#                key candidate is the actual key\n",
    "#   - partitions: The number of partitions of the key full key.\n",
    "# return: A 2D array rank. The value rank[i] are the key guess rankings for partition i. \n",
    "#         The value of rank[i][0] is the highest ranked key guess for partition i.\n",
    "def score_and_rank(traces, score_fcn, key_candidates, partitions):\n",
    "        ranks = []\n",
    "        # for each key partition        \n",
    "        for i in range(partitions): \n",
    "            dtype = [('key', int), ('score', 'float64')]\n",
    "            partition_scores = np.array([], dtype=dtype)\n",
    "            \n",
    "            # for each key guess in the partition score the value and add to list\n",
    "            for k in key_candidates:\n",
    "                score_k = score_fcn(traces, k)\n",
    "                key_score = np.array([(k, score_k)], dtype=dtype)\n",
    "                partition_scores = np.append(partition_scores, key_score)\n",
    "                \n",
    "            # rank each key where partition_ranks[0] is the key that scored the highest\n",
    "            partition_ranks = np.array([key_score[0] for key_score in np.sort(partition_scores, order='score')[::-1]])\n",
    "            \n",
    "            ranks.append(partition_ranks)\n",
    "        return ranks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T01:52:12.605175600Z",
     "start_time": "2023-11-24T01:52:12.498484300Z"
    }
   },
   "id": "45dde6602bcdcbc7"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Success Rate and Guessing Entropy Metric: Analyzes the security of a device by determining if the correct key was ranked number 1 for a given experiement\n",
    "#   - correct_keys: An array of correct cryptographic keys. The value of correct_key[0] is the correct key for experiment 0\n",
    "#   - ranks: The ranks of key guesses for a given experiment \n",
    "#   - num_experiments: The number of experiments conducted\n",
    "# return: The values of success_rate and guessing_entropy for the given number of experiments\n",
    "def success_rate_guessing_entropy(correct_keys, ranks, num_experiments):\n",
    "    success_rate = 0\n",
    "    guessing_entropy = 0\n",
    "    \n",
    "    # for each experiment\n",
    "    for i in range(num_experiments):\n",
    "        if ranks[i][0]  == correct_keys[i]:\n",
    "            success_rate += 1 # add 1 to success rate if the correct key is ranked as number 1\n",
    "        \n",
    "        # guessing entropy is the log2 of the rank of the correct key\n",
    "        guessing_entropy += math.log2(ranks[i].index(correct_keys[i]))\n",
    "    \n",
    "    success_rate = success_rate / num_experiments\n",
    "    guessing_entropy = guessing_entropy / num_experiments\n",
    "    \n",
    "    return success_rate, guessing_entropy\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T01:52:12.605175600Z",
     "start_time": "2023-11-24T01:52:12.521357600Z"
    }
   },
   "id": "3a8f43e33d17956"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Pearson's Correlation Coefficient metric\n",
    "#   - predicted_traces: predicted traces associated with intermediate values and a key guess and a plaintext value\n",
    "#   - observed_traces: actual power traces observed with a given plaintext\n",
    "# returns: the correlation coefficient and p-value between each trace\n",
    "def pearson_correlation(predicted_traces, observed_traces):\n",
    "    correlations = []\n",
    "    p_values = []\n",
    "        \n",
    "    for i in range(len(predicted_traces)):\n",
    "        correlation_coeff, p_value = stats.pearsonr(predicted_traces[i], observed_traces[i])\n",
    "        correlations.append(correlation_coeff)\n",
    "        p_values.append(p_value)\n",
    "    \n",
    "    return correlations, p_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T01:56:14.899061100Z",
     "start_time": "2023-11-24T01:56:14.829355200Z"
    }
   },
   "id": "a9557b50f10b2111"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# T-test with TVlA metric:  In general |t| > th where th = 4.5 means that the system leaks information about the cryptographic key.\n",
    "#   - fixed:  Trace set recorded with a fixed plaintext \n",
    "#   - random: Trace set recorded with a random set of plaintexts\n",
    "# return: t_statistic and p-value\n",
    "def t_test_tvla(fixed, random):\n",
    "    \n",
    "    # determine t_statistic and p-value using scipy \n",
    "    t_statistic, p_value = stats.ttest_ind(fixed, random)\n",
    "    \n",
    "    # high t-statistic and low p-values indicate that a given time sample leaks information\n",
    "    return t_statistic, p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T01:52:14.202190600Z",
     "start_time": "2023-11-24T01:52:14.088828400Z"
    }
   },
   "id": "bd9e04554a871567"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
